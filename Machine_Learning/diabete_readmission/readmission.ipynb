{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c46e725f",
   "metadata": {},
   "source": [
    "<h1 align='center'>Prediction on Readmission Rates</h1> <a id=100></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcea11eb",
   "metadata": {},
   "source": [
    "1. [Introduction](#1) <a id=18></a>\n",
    "    - 1.1 [Data Dictionary](#2)\n",
    "    - 1.2 [Task](#3)\n",
    "2. [Preparation](#4)\n",
    "    - 2.1 [Packages and Data](#5)\n",
    "    - 2.2 [Preliminary Analysis and the Final Dataset](#6)\n",
    "3. [Exploratory Data Analysis (EDA)](#7)\n",
    "    - 3.1 [Univariate Analysis](#9)\n",
    "    - 3.2 [Bivariate Analysis](#10)\n",
    "4. [Data Preprocessing](#11)\n",
    "    - 4.1 [Conclusions from the EDA](#12)\n",
    "    - 4.2 [Packages](#13)\n",
    "    - 4.3 [Making features model ready](#14)\n",
    "5. [Modeling](#15)\n",
    "    - 5.1 [Linear Classifiers](#16)\n",
    "    - 5.2 [Tree Models](#17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca92430e",
   "metadata": {},
   "source": [
    "### Introduction <a id=1></a>\n",
    "[back to top](#100)\n",
    "\n",
    "The dataset represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes. Information was extracted from the database for encounters that satisfied the following criteria.\n",
    "\n",
    "(1) It is an inpatient encounter (a hospital admission).\n",
    "\n",
    "(2) It is a diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a diagnosis.\n",
    "\n",
    "(3) The length of stay was at least 1 day and at most 14 days.\n",
    "\n",
    "(4) Laboratory tests were performed during the encounter.\n",
    "\n",
    "(5) Medications were administered during the encounter.\n",
    "\n",
    "The data contains such attributes as patient number, race, gender, age, admission type, time in hospital, medical specialty of admitting physician, number of lab test performed, HbA1c test result, diagnosis, number of medication, diabetic medications, number of outpatient, inpatient, and emergency visits in the year before the hospitalization, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60f6c82",
   "metadata": {},
   "source": [
    "#### 1.1 Data Dictionary <a id=2></a>\n",
    "`encounter_id` - Unique identifier of an encounter\n",
    "\n",
    "`patient_nbr` - Unique identifier of a patient\n",
    "\n",
    "`race` - Values: Caucasian, Asian, African American, Hispanic, and other\n",
    "\n",
    "`gender` - Values: male, female, and unknown/invalid\n",
    "\n",
    "`age` - Grouped in 10-year intervals: [0,10), [10,20), …, [90,100)\n",
    "\n",
    "`weight` - Weight in pounds.\n",
    "\n",
    "`admission_type_id` - Integer identifier corresponding to 9 distinct values, for example, emergency, urgent, elective, newborn, and not available\t\n",
    "\n",
    "`discharge_disposition_id`  - Integer identifier corresponding to 29 distinct values, for example, discharged to home, expired, and not available\t\n",
    "\n",
    "`admission_source_id` - Integer identifier corresponding to 21 distinct values, for example, physician referral, emergency room, and transfer from a hospital\n",
    "\n",
    "`time_in_hospital` - Integer number of days between admission and discharge (1~14)\n",
    "\n",
    "`payer_code` - Integer identifier corresponding to 23 distinct values, for example, Blue Cross/Blue Shield, Medicare, and self-pay\t\n",
    "\n",
    "`medical_specialty` - Integer identifier of a specialty of the admitting physician, corresponding to 84 distinct values, for example, cardiology, internal medicine, family/general practice, and surgeon\n",
    "\n",
    "`num_lab_procedures` - Number of lab tests performed during the encounter\t\n",
    "\n",
    "`num_procedures` - Number of procedures (other than lab tests) performed during the encounter\n",
    "\n",
    "`num_medications` - Number of distinct generic names administered during the encounter\n",
    "\n",
    "`number_outpatient` - Number of outpatient visits of the patient in the year preceding the encounter\t\n",
    "\n",
    "`number_emergency` - Number of emergency visits of the patient in the year preceding the encounter\t\n",
    "\n",
    "`number_inpatient` - Number of inpatient visits of the patient in the year preceding the encounter\t\n",
    "\n",
    "`diag_1` - The primary diagnosis (coded as first three digits of ICD9); 848 distinct values\t\n",
    "\n",
    "`diag_2` - Secondary diagnosis (coded as first three digits of ICD9); 923 distinct values\t\n",
    "\n",
    "`diag_3` - Additional secondary diagnosis (coded as first three digits of ICD9); 954 distinct values\t\n",
    "\n",
    "`number_diagnoses` - Number of diagnoses entered to the system\t\n",
    "\n",
    "`max_glu_serum` - Indicates the range of the result or if the test was not taken. Values: “>200,” “>300,” “normal,” and “none” if not measured\t\n",
    "\n",
    "`A1Cresult` - Indicates the range of the result or if the test was not taken. Values: “>8” if the result was greater than 8%, “>7” if the result was greater than 7% but less than 8%, “normal” if the result was less than 7%, and “none” if not measured.\t\n",
    "\n",
    "23 features for medications -\n",
    "\n",
    "`metformin`, \n",
    "`repaglinide`, `nateglinide`, `chlorpropamide`,\n",
    "`glimepiride`, `acetohexamide`, `glipizide`, `glyburide`, `tolbutamide`, `pioglitazone`,\n",
    "`rosiglitazone`, `acarbose`, `miglitol`, `troglitazone`, `tolazamide`, `examide`, `sitagliptin`, `insulin`,\n",
    "`glyburide-metformin`, `glipizide-metformin`, `glimepiride-pioglitazone`,\n",
    "`metformin-rosiglitazone`, `metformin-pioglitazone`, the feature indicates whether\n",
    "the drug was prescribed or there was a change in the dosage. Values: “up” if the dosage\n",
    "was increased during the encounter, “down” if the dosage was decreased, “steady” if the\n",
    "dosage did not change, and “no” if the drug was not prescribed\n",
    "\n",
    "\n",
    "`change` - Indicates if there was a change in diabetic medications (either dosage or generic name). Values: “change” and “no change”\n",
    "\n",
    "`diabetesMed` - Indicates if there was any diabetic medication prescribed. Values: “yes” and “no”\t\n",
    "\n",
    "`readmitted` - Days to inpatient readmission. Values: “<30” if the patient was readmitted in less than 30 days, “>30” if the patient was readmitted in more than 30 days, and “No” for no record of readmission.\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afaa16",
   "metadata": {},
   "source": [
    "### 2. Preparation <a id=4></a>\n",
    "[back to top](#100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc1576",
   "metadata": {},
   "source": [
    "#### 2.1 Import Packages and Load Data <a id=5></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b70c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "216cade0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<30' '>30' 'NO']\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "df = pd.read_csv(\"/Users/kaiwenliu/Documents/Communication Requirement/diabete/dataset_diabetes/diabetic_data.csv\")\n",
    "name_map = pd.read_csv(\"/Users/kaiwenliu/Documents/Communication Requirement/diabete/dataset_diabetes/IDs_mapping.csv\")\n",
    "\n",
    "\n",
    "X = df.drop(columns=['readmitted']) #  features\n",
    "y = df['readmitted'] #  target variable\n",
    "\n",
    "# Convert the categorical target variable into numeric format\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "279ee63a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # find the indices where the blank lines are located\n",
    "# blank_line_indices = name_map.index[name_map.isnull().all(1)]\n",
    "\n",
    "# # split the DataFrame into three separate DataFrames\n",
    "# admission_type_id_map = name_map.iloc[:blank_line_indices[0]]\n",
    "# discharge_disposition_id_map = name_map.iloc[blank_line_indices[0]+1:blank_line_indices[1]]\n",
    "# dfadmission_source_id3 = name_map.iloc[blank_line_indices[1]+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2070be8",
   "metadata": {},
   "source": [
    "#### 2.2 Final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf115605",
   "metadata": {},
   "source": [
    "##### 2.2.1 Drop dependent observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57696f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an operation to drop certain ovservationsa\n",
    "class DropObservations(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # id to remove for redundancy\n",
    "        self.id_remove = []\n",
    "        # id to remove for certain values in discharge_disposition_id        \n",
    "        self.id_remove_dd = []\n",
    "        self.rmPool = set([11,13,14,19,20,26])\n",
    "     \n",
    "    def update_drop_list(self,X):\n",
    "        # We thus used only one encounter per patient; in particular, \n",
    "        # we considered only the first encounter for each patient as the primary admission and \n",
    "        # determined whether or not they were readmitted within 30 days. \n",
    "\n",
    "        patient_id_pool = set()\n",
    "        for ind, val in X['patient_nbr'].items():\n",
    "            if val in patient_id_pool:\n",
    "                self.id_remove.append(ind)\n",
    "            else:\n",
    "                patient_id_pool.add(val)\n",
    "        \n",
    "        # Additionally, we removed all encounters that resulted in either discharge to a hospice \n",
    "        # (corresponeds to discharge_disposition_id=[13,14,19,20,26]) or \n",
    "        # patient death (correspondes to discharge_disposition_id=11), \n",
    "        # to avoid biasing our analysis.\n",
    "        \n",
    "        for i,v in X['discharge_disposition_id'].items():\n",
    "            if v in self.rmPool:\n",
    "                self.id_remove_dd.append(i)\n",
    "                        \n",
    "    def fit_transform(self, X, y):\n",
    "        X_new = X.reset_index(drop=True)\n",
    "        y_new = pd.Series(y)\n",
    "        self.update_drop_list(X_new)\n",
    "        # drop rows according to the ids and return\n",
    "        ind_drop = self.id_remove+self.id_remove_dd\n",
    "        return [X_new.drop(index=ind_drop), y_new.drop(index=ind_drop) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36f33eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the current dataset is: (69973, 49)\n"
     ]
    }
   ],
   "source": [
    "obj = DropObservations()\n",
    "X,y = obj.fit_transform(X,y)\n",
    "print(f'The shape of the current dataset is: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af356615",
   "metadata": {},
   "source": [
    "##### Check the distribution of the response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43a555c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    41474\n",
      "1    22222\n",
      "0     6277\n",
      "dtype: int64\n",
      "0: <30,\n",
      "1: >30,\n",
      "2: NO\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())\n",
    "print(f'0: {le.classes_[0]},\\n1: {le.classes_[1]},\\n2: {le.classes_[2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39917b51",
   "metadata": {},
   "source": [
    "#### 2.2.2 Split dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3254376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)\n",
    "\n",
    "# Next, use stratified sampling to further split the training set into training and validation sets\n",
    "strat_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=3202)\n",
    "\n",
    "for train_index, val_index in strat_split.split(X_train, y_train):\n",
    "    X_train_split, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_split, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "X_train = X_train_split\n",
    "y_train = y_train_split\n",
    "\n",
    "# reset index, make it starts from 0\n",
    "X_train.reset_index(drop=True,inplace=True)\n",
    "y_train.reset_index(drop=True,inplace=True)\n",
    "\n",
    "X_test.reset_index(drop=True,inplace=True)\n",
    "y_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "X_val.reset_index(drop=True,inplace=True)\n",
    "y_val.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "917947f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training dataset is (44782, 49)\n",
      "The shape of the testing dataset is (13995, 49)\n",
      "The shape of the validation dataset is (11196, 49)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of the training dataset is {X_train.shape}')\n",
    "print(f'The shape of the testing dataset is {X_test.shape}')\n",
    "print(f'The shape of the validation dataset is {X_val.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3072dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    26556\n",
       "1    14190\n",
       "0     4036\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f224f87",
   "metadata": {},
   "source": [
    "### Impute gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca061c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    23768\n",
       "Male      21014\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(X_train['gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "915acc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values = 'Unknown/Invalid',strategy='most_frequent')\n",
    "imputer.fit(X_train[['gender']])\n",
    "new_X = imputer.transform(X_train[['gender']])\n",
    "X_train['gender'] = new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57e36d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Female    23768\n",
       "Male      21014\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079b743",
   "metadata": {},
   "source": [
    "##### 2.2.2 Group the categories from ICD-9 based on common attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4793b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# icd9 codes and groups\n",
    "# circulatory: 390–459, 785\n",
    "# respiratory: 460–519, 786\n",
    "# digestive: 520–579, 787\n",
    "# diabetes: 250.xx\n",
    "# injury: 800–999\n",
    "# musculoskeletal: 710–739\n",
    "# genitourinary: 580–629, 788\n",
    "# neoplasms: 140–239\n",
    "# other: other\n",
    "\n",
    "def getICD9Group(val):\n",
    "    category = ''\n",
    "    try:\n",
    "        num = int(float(val))\n",
    "        if (num >=390 and num <=459 ) or num == 785:\n",
    "            category = 'circulatory'\n",
    "        elif (num >= 460 and num <= 519) or num == 786:\n",
    "            category = 'respiratory'\n",
    "        elif (num >= 520 and num <= 579) or num == 787:\n",
    "            category = 'digestive'\n",
    "        elif num==250:\n",
    "            category = 'diabetes'\n",
    "        elif num >= 800 and num <= 999:\n",
    "            category = 'injury'\n",
    "        elif num >= 710 and num <= 739:\n",
    "            category = 'musculoskeletal'\n",
    "        elif (num >= 580 and num <= 629) or num == 788:\n",
    "            category = 'genitourinary'\n",
    "        elif num >= 140 and num <= 239:\n",
    "            category = 'neoplasms'\n",
    "        else:\n",
    "            category = 'other'\n",
    "    except ValueError:\n",
    "        category = 'other'\n",
    "    return category\n",
    "\n",
    "def getNewColumnByICD9Group(df, col, name):\n",
    "    newCol = []\n",
    "    for i, val in df[col].items():\n",
    "        newCol.append(getICD9Group(val))\n",
    "    return pd.Series(newCol, name = name)\n",
    "\n",
    "# newCol_diag1 = getNewColumnByICD9Group(df_new, 'diag_1', 'diag_1_new')\n",
    "# newCol_diag2 = getNewColumnByICD9Group(df_new, 'diag_2', 'diag_2_new')\n",
    "# newCol_diag3 = getNewColumnByICD9Group(df_new, 'diag_3', 'diag_3_new')\n",
    "\n",
    "\n",
    "# create an operation to group the categories from ICD-9 based on common attributes.\n",
    "class GroupICD9IntoCatefories(BaseEstimator, TransformerMixin):\n",
    "    def transform(self, X):\n",
    "        newCol_diag1 = getNewColumnByICD9Group(X, 'diag_1', 'diag_1_new')\n",
    "        newCol_diag2 = getNewColumnByICD9Group(X, 'diag_2', 'diag_2_new')\n",
    "        newCol_diag3 = getNewColumnByICD9Group(X, 'diag_3', 'diag_3_new')\n",
    "        df_new0 = X.reset_index()\n",
    "        df_new1 = pd.concat([df_new0,newCol_diag1], axis=1)\n",
    "        df_new2 = pd.concat([df_new1,newCol_diag2], axis=1)\n",
    "        df_new3 = pd.concat([df_new2,newCol_diag3], axis=1)\n",
    "        return df_new3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "874a97bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the current dataset is: (44782, 53)\n"
     ]
    }
   ],
   "source": [
    "obj = GroupICD9IntoCatefories()\n",
    "X_train1 = obj.transform(X_train)\n",
    "print(f'The shape of the current dataset is: {X_train1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4033df80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other              13466\n",
       "circulatory        13410\n",
       "diabetes            8106\n",
       "respiratory         2986\n",
       "genitourinary       2578\n",
       "digestive           1722\n",
       "injury               908\n",
       "musculoskeletal      897\n",
       "neoplasms            709\n",
       "Name: diag_3_new, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "X_train1['diag_3_new'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899fccb9",
   "metadata": {},
   "source": [
    "##### 2.2.2 Drop unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06cb5a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>44782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <td>44782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_nbr</th>\n",
       "      <td>44782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admission_type_id</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admission_source_id</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_in_hospital</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payer_code</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_specialty</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_procedures</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_medications</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_outpatient</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_emergency</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_inpatient</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_1</th>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_2</th>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_3</th>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_diagnoses</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_glu_serum</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1Cresult</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metformin</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>repaglinide</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nateglinide</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chlorpropamide</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glimepiride</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acetohexamide</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glipizide</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glyburide</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolbutamide</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pioglitazone</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rosiglitazone</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acarbose</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miglitol</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>troglitazone</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolazamide</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>examide</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citoglipton</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insulin</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetesMed</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_1_new</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_2_new</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diag_3_new</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          num_unique\n",
       "index                          44782\n",
       "encounter_id                   44782\n",
       "patient_nbr                    44782\n",
       "race                               6\n",
       "gender                             2\n",
       "age                               10\n",
       "weight                            10\n",
       "admission_type_id                  8\n",
       "discharge_disposition_id          21\n",
       "admission_source_id               17\n",
       "time_in_hospital                  14\n",
       "payer_code                        17\n",
       "medical_specialty                 67\n",
       "num_lab_procedures               110\n",
       "num_procedures                     7\n",
       "num_medications                   74\n",
       "number_outpatient                 30\n",
       "number_emergency                  17\n",
       "number_inpatient                  13\n",
       "diag_1                           644\n",
       "diag_2                           669\n",
       "diag_3                           697\n",
       "number_diagnoses                  16\n",
       "max_glu_serum                      4\n",
       "A1Cresult                          4\n",
       "metformin                          4\n",
       "repaglinide                        4\n",
       "nateglinide                        4\n",
       "chlorpropamide                     4\n",
       "glimepiride                        4\n",
       "acetohexamide                      1\n",
       "glipizide                          4\n",
       "glyburide                          4\n",
       "tolbutamide                        2\n",
       "pioglitazone                       4\n",
       "rosiglitazone                      4\n",
       "acarbose                           3\n",
       "miglitol                           4\n",
       "troglitazone                       2\n",
       "tolazamide                         2\n",
       "examide                            1\n",
       "citoglipton                        1\n",
       "insulin                            4\n",
       "glyburide-metformin                4\n",
       "glipizide-metformin                2\n",
       "glimepiride-pioglitazone           1\n",
       "metformin-rosiglitazone            2\n",
       "metformin-pioglitazone             2\n",
       "change                             2\n",
       "diabetesMed                        2\n",
       "diag_1_new                         9\n",
       "diag_2_new                         9\n",
       "diag_3_new                         9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of unqiue values of each variable\n",
    "def check_unique_values(df):\n",
    "    num_unique = pd.DataFrame(df.nunique())\n",
    "    num_unique.columns = ['num_unique']\n",
    "    return num_unique\n",
    "\n",
    "check_unique_values(X_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79e5104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove weight and payer code since they have a high percentage of missing values\n",
    "# (This is indicated in the paper[https://www.hindawi.com/journals/bmri/2014/781670/#introduction]\n",
    "# drop 'examide', 'citoglipton' and 'glimepiride-pioglitazone' because they have only one category\n",
    "# df = df_new3.drop(columns=['weight', 'payer_code', 'encounter_id', 'patient_nbr', 'diag_1', 'diag_2', 'diag_3', 'index', 'examide', 'citoglipton', 'glimepiride-pioglitazone'])\n",
    "\n",
    "# check duplicates\n",
    "# print(f\"The number of duplicates: {df.duplicated().sum()}\")\n",
    "\n",
    "\n",
    "class DropFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features_drop = features\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.features_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "736c8552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the current dataset is: (44782, 42)\n"
     ]
    }
   ],
   "source": [
    "# since 'examide', 'citoglipton' and 'glimepiride-pioglitazone' have only one category, they can be dropped\n",
    "drop_list=['weight', 'payer_code', 'encounter_id', 'patient_nbr', 'diag_1', 'diag_2', \n",
    "           'diag_3', 'examide','index', 'citoglipton', 'glimepiride-pioglitazone']\n",
    "obj = DropFeatures(drop_list)\n",
    "X_train2 = obj.transform(X_train1)\n",
    "print(f'The shape of the current dataset is: {X_train2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f87887b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['race', 'gender', 'age', 'admission_type_id',\n",
       "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
       "       'medical_specialty', 'num_lab_procedures', 'num_procedures',\n",
       "       'num_medications', 'number_outpatient', 'number_emergency',\n",
       "       'number_inpatient', 'number_diagnoses', 'max_glu_serum', 'A1Cresult',\n",
       "       'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide',\n",
       "       'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
       "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
       "       'tolazamide', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
       "       'metformin-rosiglitazone', 'metformin-pioglitazone', 'change',\n",
       "       'diabetesMed', 'diag_1_new', 'diag_2_new', 'diag_3_new'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "X_train2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2fbd58",
   "metadata": {},
   "source": [
    "#### 2.4 Preliminary Analysis <a id=6></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c17dcc",
   "metadata": {},
   "source": [
    "##### 2.3.3 Group infrequent values into one a single category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "257ff112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the proportion of each category\n",
    "def checkCategoryProp(se):\n",
    "    counts = se.value_counts()\n",
    "    prop = counts/counts.sum()\n",
    "    return pd.DataFrame({\n",
    "        'category': counts.index,\n",
    "        'count': counts,\n",
    "        'proportion': prop\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a63e147",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pulmonology',\n",
       " 'Psychiatry',\n",
       " 'ObstetricsandGynecology',\n",
       " 'Urology',\n",
       " 'Surgery-Cardiovascular/Thoracic',\n",
       " 'Surgery-Neuro',\n",
       " 'Gastroenterology',\n",
       " 'Surgery-Vascular',\n",
       " 'Oncology',\n",
       " 'Pediatrics',\n",
       " 'PhysicalMedicineandRehabilitation',\n",
       " 'Neurology',\n",
       " 'Pediatrics-Endocrinology',\n",
       " 'Hematology/Oncology',\n",
       " 'Otolaryngology',\n",
       " 'Surgery-Thoracic',\n",
       " 'Endocrinology',\n",
       " 'Surgery-Cardiovascular',\n",
       " 'Podiatry',\n",
       " 'Pediatrics-CriticalCare',\n",
       " 'Psychology',\n",
       " 'Gynecology',\n",
       " 'Surgeon',\n",
       " 'Radiology',\n",
       " 'Osteopath',\n",
       " 'Hematology',\n",
       " 'Hospitalist',\n",
       " 'Ophthalmology',\n",
       " 'Surgery-Plastic',\n",
       " 'InfectiousDiseases',\n",
       " 'SurgicalSpecialty',\n",
       " 'Anesthesiology-Pediatric',\n",
       " 'Obstetrics',\n",
       " 'Obsterics&Gynecology-GynecologicOnco',\n",
       " 'Surgery-Colon&Rectal',\n",
       " 'OutreachServices',\n",
       " 'PhysicianNotFound',\n",
       " 'Cardiology-Pediatric',\n",
       " 'Pathology',\n",
       " 'Pediatrics-Pulmonology',\n",
       " 'Anesthesiology',\n",
       " 'Rheumatology',\n",
       " 'Pediatrics-EmergencyMedicine',\n",
       " 'Psychiatry-Child/Adolescent',\n",
       " 'Surgery-Maxillofacial',\n",
       " 'Endocrinology-Metabolism',\n",
       " 'Surgery-Pediatric',\n",
       " 'DCPTEAM',\n",
       " 'Pediatrics-Neurology',\n",
       " 'AllergyandImmunology',\n",
       " 'Dentistry',\n",
       " 'Dermatology',\n",
       " 'Perinatology',\n",
       " 'Proctology',\n",
       " 'Surgery-PlasticwithinHeadandNeck',\n",
       " 'Resident',\n",
       " 'Speech']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(check_unique_values(df_new3))\n",
    "# checkCategoryProp(df_new3['admission_type_id'])\n",
    "# checkCategoryProp(df_new3['discharge_disposition_id'])\n",
    "# checkCategoryProp(df_new3['admission_source_id'])\n",
    "table = checkCategoryProp(X_train2['medical_specialty'])\n",
    "table[checkCategoryProp(X_train2['medical_specialty'])['proportion'] < 0.01]['category'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "069f3c62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# group infrequent values into one a single category\n",
    "def group_infrequent_category(df, col_name, threshold, group_value):\n",
    "    # change all the values that are below the threshold to the groupValue\n",
    "    # return removed categories \n",
    "    table = checkCategoryProp(df[col_name])\n",
    "    vals_to_group = table[(table['proportion'] < threshold)]['category'].tolist()\n",
    "    df[col_name].replace(vals_to_group, group_value, inplace=True) \n",
    "    return vals_to_group\n",
    "\n",
    "# create an operation to group infrequent values into one a single category\n",
    "class GroupInfrequentCategories(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, use_past_result=False, dict_cols_cats={}):\n",
    "        self.use_past_result = use_past_result\n",
    "        self.dict_cols_cats = dict_cols_cats\n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.use_past_result:\n",
    "            X['discharge_disposition_id'].replace(self.dict_cols_cats['discharge_disposition_id'], 0, inplace=True)\n",
    "            X['admission_source_id'].replace(self.dict_cols_cats['admission_source_id'], 0, inplace=True)\n",
    "            X['medical_specialty'].replace(self.dict_cols_cats['medical_specialty'], 'other', inplace=True)         \n",
    "            \n",
    "        else:\n",
    "            dd_vals = group_infrequent_category(X,'discharge_disposition_id', 0.01, 0)\n",
    "            ads_vals = group_infrequent_category(X, 'admission_source_id', 0.01, 0)\n",
    "            ms_vals = group_infrequent_category(X, 'medical_specialty', 0.01, 'other')\n",
    "#             store the results\n",
    "            self.dict_cols_cats = {\n",
    "                'discharge_disposition_id': dd_vals,\n",
    "                'admission_source_id': ads_vals,\n",
    "                'medical_specialty': ms_vals,\n",
    "            }\n",
    "            \n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1969eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the current dataset is: (44782, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>?</td>\n",
       "      <td>21465</td>\n",
       "      <td>0.479322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InternalMedicine</th>\n",
       "      <td>InternalMedicine</td>\n",
       "      <td>6787</td>\n",
       "      <td>0.151556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>other</td>\n",
       "      <td>3929</td>\n",
       "      <td>0.087736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family/GeneralPractice</th>\n",
       "      <td>Family/GeneralPractice</td>\n",
       "      <td>3190</td>\n",
       "      <td>0.071234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emergency/Trauma</th>\n",
       "      <td>Emergency/Trauma</td>\n",
       "      <td>2807</td>\n",
       "      <td>0.062681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cardiology</th>\n",
       "      <td>Cardiology</td>\n",
       "      <td>2714</td>\n",
       "      <td>0.060605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surgery-General</th>\n",
       "      <td>Surgery-General</td>\n",
       "      <td>1408</td>\n",
       "      <td>0.031441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedics</th>\n",
       "      <td>Orthopedics</td>\n",
       "      <td>729</td>\n",
       "      <td>0.016279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Orthopedics-Reconstructive</th>\n",
       "      <td>Orthopedics-Reconstructive</td>\n",
       "      <td>717</td>\n",
       "      <td>0.016011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Radiologist</th>\n",
       "      <td>Radiologist</td>\n",
       "      <td>529</td>\n",
       "      <td>0.011813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nephrology</th>\n",
       "      <td>Nephrology</td>\n",
       "      <td>507</td>\n",
       "      <td>0.011322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              category  count  proportion\n",
       "?                                                    ?  21465    0.479322\n",
       "InternalMedicine                      InternalMedicine   6787    0.151556\n",
       "other                                            other   3929    0.087736\n",
       "Family/GeneralPractice          Family/GeneralPractice   3190    0.071234\n",
       "Emergency/Trauma                      Emergency/Trauma   2807    0.062681\n",
       "Cardiology                                  Cardiology   2714    0.060605\n",
       "Surgery-General                        Surgery-General   1408    0.031441\n",
       "Orthopedics                                Orthopedics    729    0.016279\n",
       "Orthopedics-Reconstructive  Orthopedics-Reconstructive    717    0.016011\n",
       "Radiologist                                Radiologist    529    0.011813\n",
       "Nephrology                                  Nephrology    507    0.011322"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = GroupInfrequentCategories()\n",
    "obj.transform(X_train2)\n",
    "\n",
    "# parameters to input for test data\n",
    "dict_cols_cats = obj.dict_cols_cats\n",
    "\n",
    "print(f'The shape of the current dataset is: {X_train2.shape}')\n",
    "checkCategoryProp(X_train2['medical_specialty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24869e",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis (EDA) <a id=7></a>\n",
    "[back to top](#100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14db0c8",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### 3.1 Univariate Analysis <a id=9></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02360dcd",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "##### 3.1.1 Split features into categorical and numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf6ca4e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44782, 42)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d83afa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "categorical_features = ['race', 'gender', 'age', 'admission_type_id','discharge_disposition_id', \n",
    "                        'admission_source_id', 'medical_specialty', 'max_glu_serum', 'A1Cresult',\n",
    "                        'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
    "                        'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',\n",
    "                        'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'insulin',\n",
    "                        'glyburide-metformin', 'glipizide-metformin', 'metformin-rosiglitazone',\n",
    "                        'metformin-pioglitazone', 'change', 'diabetesMed', 'diag_1_new', 'diag_2_new',\n",
    "                        'diag_3_new'\n",
    "                       ]\n",
    "\n",
    "numerical_features = ['time_in_hospital', 'num_lab_procedures', 'num_procedures', 'num_medications', \n",
    "                      'number_outpatient', 'number_emergency','number_inpatient', 'number_diagnoses']\n",
    "\n",
    "print(len(categorical_features))\n",
    "print(len(numerical_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c493e5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert selected columns to categorical dtype\n",
    "# for col in categorical_features:\n",
    "#     [col] = df_new3[col].astype('category')\n",
    "    \n",
    "\n",
    "# create an operation to change type of certain columns\n",
    "class ChangeColumnType(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_features):\n",
    "        self.categorical_features = categorical_features\n",
    "        \n",
    "    def transform(self, X):\n",
    "        for col in self.categorical_features:\n",
    "            X[col] = X[col].astype('category')\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21c8b177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race                        category\n",
      "gender                      category\n",
      "age                         category\n",
      "admission_type_id           category\n",
      "discharge_disposition_id    category\n",
      "admission_source_id         category\n",
      "time_in_hospital               int64\n",
      "medical_specialty           category\n",
      "num_lab_procedures             int64\n",
      "num_procedures                 int64\n",
      "num_medications                int64\n",
      "number_outpatient              int64\n",
      "number_emergency               int64\n",
      "number_inpatient               int64\n",
      "number_diagnoses               int64\n",
      "max_glu_serum               category\n",
      "A1Cresult                   category\n",
      "metformin                   category\n",
      "repaglinide                 category\n",
      "nateglinide                 category\n",
      "chlorpropamide              category\n",
      "glimepiride                 category\n",
      "acetohexamide               category\n",
      "glipizide                   category\n",
      "glyburide                   category\n",
      "tolbutamide                 category\n",
      "pioglitazone                category\n",
      "rosiglitazone               category\n",
      "acarbose                    category\n",
      "miglitol                    category\n",
      "troglitazone                category\n",
      "tolazamide                  category\n",
      "insulin                     category\n",
      "glyburide-metformin         category\n",
      "glipizide-metformin         category\n",
      "metformin-rosiglitazone     category\n",
      "metformin-pioglitazone      category\n",
      "change                      category\n",
      "diabetesMed                 category\n",
      "diag_1_new                  category\n",
      "diag_2_new                  category\n",
      "diag_3_new                  category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "obj = ChangeColumnType(categorical_features)\n",
    "obj.transform(X_train2)\n",
    "print(X_train2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67893061",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### 3.1.2 Chi-Square test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dfc92c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def chi2_test(x, y, col):\n",
    "#     # Compute the contingency table\n",
    "#     contingency_table = pd.crosstab(x[col], y)\n",
    "#     # Compute the chi-square test statistic and p-value\n",
    "#     chi2, pval, dof, expected = chi2_contingency(contingency_table)\n",
    "#     return [chi2, pval, dof, expected]\n",
    "\n",
    "# chi2s = []\n",
    "# pvals = []\n",
    "# dofs = []\n",
    "# for c in categorical_features:\n",
    "#     chi2, pval, dof, _ = chi2_test(X_train2,y_train,c)\n",
    "#     chi2s.append(chi2)\n",
    "#     pvals.append(pval)\n",
    "#     dofs.append(dof)\n",
    "\n",
    "\n",
    "# significant = ['*' if x<0.05 else '' for x in pvals]\n",
    "\n",
    "# chi2_table = pd.DataFrame({\n",
    "#     'chi2': chi2s,\n",
    "#     'pval': pvals,\n",
    "#     'dof': dofs,\n",
    "#     'significance': significant,\n",
    "# })\n",
    "\n",
    "# index_drop = [ind for ind, val in enumerate(pvals) if val>=0.05]\n",
    "\n",
    "\n",
    "# create an operation to change type of certain columns\n",
    "class drop_features_with_low_chi2_pval(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, categorical_features, significance_level=0.1):\n",
    "        self.index_drop = []\n",
    "        self.significance_level = significance_level\n",
    "        self.table = pd.DataFrame\n",
    "        self.categorical_features=categorical_features\n",
    "        \n",
    "#     function of conducting chi-square test\n",
    "    def chi2_test(cls, X, y, col):\n",
    "        # Compute the contingency table\n",
    "        contingency_table = pd.crosstab(X[col], y)\n",
    "        # Compute the chi-square test statistic and p-value\n",
    "        chi2, pval, dof, expected = chi2_contingency(contingency_table)\n",
    "        return [chi2, pval, dof, expected]\n",
    "\n",
    "    def plot_chi2_table(self, X, y):\n",
    "        chi2s = []\n",
    "        pvals = []\n",
    "        dofs = []\n",
    "        for c in self.categorical_features:\n",
    "            chi2, pval, dof, _ = self.chi2_test(X,y,c)\n",
    "            chi2s.append(chi2)\n",
    "            pvals.append(pval)\n",
    "            dofs.append(dof)\n",
    "\n",
    "        significant = ['*' if x<self.significance_level else '' for x in pvals]\n",
    "\n",
    "        chi2_table = pd.DataFrame({\n",
    "            'chi2': chi2s,\n",
    "            'pval': pvals,\n",
    "            'dof': dofs,\n",
    "            'significance': significant,\n",
    "        })\n",
    "\n",
    "        return chi2_table\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.table = self.plot_chi2_table(X, y)\n",
    "        pvals = self.table['pval']\n",
    "        self.index_drop = [ind for ind, val in enumerate(pvals) if val>=self.significance_level]\n",
    "        \n",
    "    def transform(self, X):\n",
    "        cols = [self.categorical_features[i] for i in self.index_drop]\n",
    "        return X.drop(columns=cols)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "189d96a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj = drop_features_with_low_chi2_pval()\n",
    "# obj.plot_chi2_table(X_train2,y_train, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb4fdad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44782, 29)\n"
     ]
    }
   ],
   "source": [
    "obj = drop_features_with_low_chi2_pval(categorical_features)\n",
    "obj.fit(X_train2, y_train)\n",
    "X_train3 = obj.transform(X_train2)\n",
    "print(X_train3.shape)\n",
    "columns_dropped_due_to_chi2_test = [categorical_features[i] for i in obj.index_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a644ebff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glyburide', 'tolbutamide', 'miglitol', 'troglitazone', 'tolazamide', 'glyburide-metformin', 'glipizide-metformin', 'metformin-rosiglitazone', 'metformin-pioglitazone']\n"
     ]
    }
   ],
   "source": [
    "print(columns_dropped_due_to_chi2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7715656",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 4. Preparing data for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7516cfd0",
   "metadata": {},
   "source": [
    "#### 5.1 Handle categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b8fe5d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create an operation to get dummy varibles of categorical variables\n",
    "class GetDummyVariable(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_features):\n",
    "        self.categorical_features = categorical_features\n",
    "    \n",
    "    def replace_illegal_name(self, X_train_dummies):\n",
    "        # replace '[', ']' and '<' because they are invalud as column names in xgboost\n",
    "        # replace '[' with '('; '<' with 'less than'; '>' with 'greater than'\n",
    "        for s in X_train_dummies.columns:\n",
    "            new_name = re.sub(r'\\[', '(', s)\n",
    "            X_train_dummies.rename(columns={s:new_name},inplace=True)\n",
    "\n",
    "        for s in X_train_dummies.columns:\n",
    "            new_name = re.sub(r'\\<', 'less_than', s)\n",
    "            X_train_dummies.rename(columns={s:new_name},inplace=True)\n",
    "\n",
    "        for s in X_train_dummies.columns:\n",
    "            new_name = re.sub(r'\\>', 'greater_than', s)\n",
    "            X_train_dummies.rename(columns={s:new_name},inplace=True)\n",
    "        return X_train_dummies\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # get dummy variables\n",
    "        X_train_dummies = pd.get_dummies(X, columns=self.categorical_features)\n",
    "        return self.replace_illegal_name(X_train_dummies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b969a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_after_chi2 = X_train3.columns[X_train3.dtypes == 'category']\n",
    "obj = GetDummyVariable(categorical_features_after_chi2)\n",
    "X_train4 = obj.transform(X_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5dd71cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44782, 127)\n"
     ]
    }
   ],
   "source": [
    "print(X_train4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd3366",
   "metadata": {},
   "source": [
    "### 5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5e19c",
   "metadata": {},
   "source": [
    "#### 5.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "62a566fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(rfc, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# fit the grid search to the training data\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# print the best parameters found\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters: \u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# standardize the data\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform the data\n",
    "# X_train_scaled = scaler.fit_transform(X_train4)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rfc.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "# initialize GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=5)\n",
    "\n",
    "# fit the grid search to the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print the best parameters found\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ee5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for proprecessing\n",
    "logist_preprocessing_pipeline = Pipeline([\n",
    "    ('change ICD9 codes to categories', GroupICD9IntoCatefories()),\n",
    "    ('drop features due to dependent rows', DropFeatures(drop_list)),\n",
    "    ('group infrequent categories into one category', GroupInfrequentCategories(use_past_result=False, dict_cols_cats=dict_cols_cats)),\n",
    "    ('change column type', ChangeColumnType(categorical_features)),\n",
    "    ('drop features due to small pval in chi2 test', DropFeatures(columns_dropped_due_to_chi2_test)),\n",
    "    ('get dummy variable for cateforical variables', GetDummyVariable(categorical_features_after_chi2)),\n",
    "    ('scale', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eec348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the best model on the training data\n",
    "best_logreg = grid_search.best_estimator_\n",
    "X_val_processed = logist_preprocessing_pipeline.fit_transform()\n",
    "training_score = best_logreg.score(X_train4, y_train)\n",
    "print(\"Training accuracy: {:.3f}\".format(training_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcde00d0",
   "metadata": {},
   "source": [
    "#### 6.1 XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be391169",
   "metadata": {},
   "source": [
    "##### 6.1.1 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "45510b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'colsample_bytree': 0.5, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 500, 'num_class': 3, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# initialize XGBoost classifier\n",
    "clf = XGBClassifier(objective=\"multi:softprob\", random_state=2022)\n",
    "\n",
    "# define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [500],\n",
    "    'max_depth': [3,5],\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [0.5],\n",
    "    'colsample_bytree': [0.2,0.5],\n",
    "    'num_class': [3],\n",
    "}\n",
    "\n",
    "# initialize GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "\n",
    "# fit the grid search to the training data\n",
    "grid_search.fit(X_train4, y_train)\n",
    "\n",
    "# print the best parameters found\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a60bea34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.630\n"
     ]
    }
   ],
   "source": [
    "# evaluate the best model on the training data\n",
    "best_clf = grid_search.best_estimator_\n",
    "training_score = best_clf.score(X_train4, y_train)\n",
    "print(\"Training accuracy: {:.3f}\".format(training_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba3267fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for proprecessing\n",
    "xgboost_preprocessing_pipeline = Pipeline([\n",
    "    ('change ICD9 codes to categories', GroupICD9IntoCatefories()),\n",
    "    ('drop features due to dependent rows', DropFeatures(drop_list)),\n",
    "    ('group infrequent categories into one category', GroupInfrequentCategories(use_past_result=False, dict_cols_cats=dict_cols_cats)),\n",
    "    ('change column type', ChangeColumnType(categorical_features)),\n",
    "    ('drop features due to small pval in chi2 test', DropFeatures(columns_dropped_due_to_chi2_test)),\n",
    "    ('get dummy variable for cateforical variables', GetDummyVariable(categorical_features_after_chi2))   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8447da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed = xgboost_preprocessing_pipeline.transform(X_test)\n",
    "X_train_pre = xgboost_preprocessing_pipeline.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "471934ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44782, 127)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f41cc910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13995, 127)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da54c31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13995,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf2fc5",
   "metadata": {},
   "source": [
    "##### 6.1.2 predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93455cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.614\n"
     ]
    }
   ],
   "source": [
    "# evaluate the best model on the test data\n",
    "best_clf = grid_search.best_estimator_\n",
    "test_score = best_clf.score(X_test_preprocessed, y_test)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc4a39",
   "metadata": {},
   "source": [
    "<h1 align='center'>Appendix</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972937c",
   "metadata": {},
   "source": [
    "\n",
    "`admission_type_id` - admission type - \\\n",
    "    Emergency = 1, \\\n",
    "    Urgent = 2, \\\n",
    "    Elective = 3, \\\n",
    "    Newborn = 4, \\\n",
    "    Not Available = 5, \\\n",
    "    Null = 6, \\\n",
    "    Trauma Center = 7, \\\n",
    "    Not Mapped = 8 \\\n",
    "\n",
    "`discharge_disposition_id`  - Discharge disposition - \\\n",
    "Discharged to home = 1, \\\n",
    "Discharged/transferred to another short term hospital = 2,\\\n",
    "Discharged/transferred to SNF = 3, \\\n",
    "Discharged/transferred to ICF = 4, \\\n",
    "Discharged/transferred to another type of inpatient care institution = 5, \\\n",
    "Discharged/transferred to home with home health service = 6, \\\n",
    "Left AMA = 7, \\\n",
    "Discharged/transferred to home under care of Home IV provider = 8, \\\n",
    "Admitted as an inpatient to this hospital = 9, \\\n",
    "Neonate discharged to another hospital for neonatal aftercare = 10, \\\n",
    "Expired = 11, \\\n",
    "Still patient or expected to return for outpatient services = 12, \\\n",
    "Hospice / home = 13, \\\n",
    "Hospice / medical facility = 14, \\\n",
    "Discharged/transferred within this institution to Medicare approved swing bed = 15, \\\n",
    "Discharged/transferred/referred another institution for outpatient services = 16, \\\n",
    "Discharged/transferred/referred to this institution for outpatient services = 17, \\\n",
    "NULL = 18, \\\n",
    "Expired at home. Medicaid only, hospice. = 19, \\\n",
    "Expired in a medical facility. Medicaid only, hospice. = 20, \\\n",
    "Discharged/transferred to another rehab fac including rehab units of a hospital . = 22, \\\n",
    "Discharged/transferred to a long term care hospital. = 23, \\\n",
    "Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare. = 24, \\\n",
    "Not Mapped = 25, \\\n",
    "Unknown/Invalid = 26, \\\n",
    "Discharged/transferred to a federal health care facility. = 27, \\\n",
    "Discharged/transferred/referred to a psychiatric hospital of psychiatric distinct part unit of a hospital = 28, \\\n",
    "Discharged/transferred to a Critical Access Hospital (CAH). = 29, \\\n",
    "Discharged/transferred to another Type of Health Care Institution not Defined Elsewhere = 30, \n",
    "\n",
    "`admission_source_id` - admission source - \\\n",
    "Physician Referral = 1, \\\n",
    "Clinic Referral = 2, \\\n",
    "HMO Referral = 3, \\\n",
    "Transfer from a hospital = 4, \\\n",
    " Transfer from a Skilled Nursing Facility (SNF) = 5, \\\n",
    " Transfer from another health care facility = 6, \\\n",
    " Emergency Room = 7, \\\n",
    " Court/Law Enforcement = 8, \\\n",
    " Not Available = 9, \\\n",
    " Transfer from critial access hospital = 10, \\\n",
    "Normal Delivery = 11, \\\n",
    " Premature Delivery = 12, \\\n",
    " Sick Baby = 13, \\\n",
    " Extramural Birth = 14, \\\n",
    "Not Available = 15, \\\n",
    "NULL = 17, \\\n",
    " Transfer From Another Home Health Agency = 18, \\\n",
    "Readmission to Same Home Health Agency = 19, \\\n",
    " Not Mapped = 20, \\\n",
    "Unknown/Invalid = 21, \\\n",
    " Transfer from hospital inpt/same fac reslt in a sep claim = 22, \\\n",
    " Born inside this hospital = 23, \\\n",
    " Born outside this hospital = 24, \\\n",
    " Transfer from Ambulatory Surgery Center = 25, \\\n",
    "Transfer from Hospice = 26,\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81798173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "209px",
    "width": "348px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
